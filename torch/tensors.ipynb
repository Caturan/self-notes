{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8b4c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4350, 0.7137, 0.6850],\n",
      "        [0.1301, 0.3340, 0.6030],\n",
      "        [0.5704, 0.8189, 0.3676],\n",
      "        [0.7260, 0.9975, 0.2228],\n",
      "        [0.9809, 0.2174, 0.4014]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b554d6",
   "metadata": {},
   "source": [
    "# Tensors \n",
    "- Tensors are a specialized data structure that are very similar to arrays and matrices. \n",
    "- In PyTorch, we use tensors to encode the inputs and outputs of a model, as well as the model's parameters. \n",
    "- Tensors are simiar to NumPy's ndarrays, except that tensors can run on GPUs or other hardware accelerators. \n",
    "- In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data. \n",
    "- Tensors are also optimized for automatic differentiation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be581d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f304cc",
   "metadata": {},
   "source": [
    "## Initializing a Tensor \n",
    "- Tensors can be initialized in various ways. Take a look at the following examples: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792c637",
   "metadata": {},
   "source": [
    "### Directly from data \n",
    "- Tensors can be created directly from data. The data type is automatically inferred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44ce116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2], [3,4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b438fa",
   "metadata": {},
   "source": [
    "### From a NumPy array \n",
    "- Tensors can be created from NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7322af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837aa13",
   "metadata": {},
   "source": [
    "### From another tensor: \n",
    "- The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden. \n",
    "- torch.ones_like() -> is a PyTorch function that creates a new tensor filled with the scalar value 1, with the same size (shape) and dtype as a given input tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a36fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.8996, 0.8796],\n",
      "        [0.7101, 0.5587]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data \n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # Overrides the datatype of x_data \n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d92ecb",
   "metadata": {},
   "source": [
    "### With random or constant values: \n",
    "- shape is a tuple of tensor dimensions. \n",
    "- In the functions below, it determines the dimensionality of the output tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f9e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3017, 0.4610, 0.2633],\n",
      "        [0.3497, 0.0200, 0.8237]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c844b4",
   "metadata": {},
   "source": [
    "## Attiributes of a Tensor \n",
    "- Tensor attributes describe their shape, datatype, and the device on which they are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "466e517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed47856",
   "metadata": {},
   "source": [
    "## Operations on Tensors \n",
    "- Over 1200 tensor operations, including arithmetic, linear algebra, matrix manipulation(transposing, indexing,slicing)..\n",
    "- Each of these operations can be run on the CPU and Accelerator such as CUDA, MPS, MTIA or XPU. \n",
    "- By default, tensors are created on the CPU. \n",
    "- We need to explicitly move tensors to the accelerator using .to method (after checking for accelerator availability.)\n",
    "- Keep in mind that copying large tensors across devices can be expensive in terms of time and memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b56dd4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the current accelerator if available \n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26bbce",
   "metadata": {},
   "source": [
    "- Try out some of the operations from the list. \n",
    "- If you are familiar with the NumPy API, you'll find the Tensor API a breeze to use. \n",
    "### Standard numpy-like indexing and slicing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c644e73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0 \n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abae08d",
   "metadata": {},
   "source": [
    "- Joining tensors, we can use torch.cat to concatenate a sequence of tensors along a given dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57eef001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a68f31",
   "metadata": {},
   "source": [
    "### Arithmetic operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc50552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same values\n",
    "# ''tensor.T'' returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value \n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c381cc5",
   "metadata": {},
   "source": [
    "- Single-element tensors if we have a one-element tensor, for example by aggregating all values of a tensor into one value, we can convert it to a Python numerical value using item():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7de878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb12e1",
   "metadata": {},
   "source": [
    "- In-place operations; Operations that store the result into the operand are called in-place. \n",
    "- They are denoted by a_suffix.\n",
    "- For example x.copy_(y)i x.t_(t), will change x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c09251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abcc718",
   "metadata": {},
   "source": [
    "- Note:\n",
    "    - In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history.\n",
    "    - Hence, their use is discouraged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207c7549",
   "metadata": {},
   "source": [
    "## Bridge with NumPy \n",
    "- Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf7dc9f",
   "metadata": {},
   "source": [
    "### Tensor to NumPy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26dd75fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcda156",
   "metadata": {},
   "source": [
    "- A change in the tensor reflects in the NumPy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5cf3106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8cc259",
   "metadata": {},
   "source": [
    "### NumPy array to Tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf573426",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aada4d",
   "metadata": {},
   "source": [
    "- Changes in the NumPy array reflects in the tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3289b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
